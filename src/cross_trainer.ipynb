{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silva\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from train.multi_hyperparameter import MultiHyperparameter\n",
    "from custom_models.unet_original import UNet, UNet2\n",
    "from evaluate.cross_evaluator import CrossTrainEvaluator\n",
    "from train.unet_trainer import UnetTrainer\n",
    "from datasets.semantic_dataset import SemanticDataset\n",
    "from preprocessing.data_augment import DataAugmenter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "params = {'padding_mode': ['zeros', 'reflect', 'replicate', 'circular'],\n",
    "          'depth': 5,\n",
    "          'start_layers': 64,\n",
    "          'dim_multiplier': 2,\n",
    "          'input_conv_kernel_size': 3,\n",
    "          'out_classes': 2,\n",
    "          'criterion': nn.CrossEntropyLoss(),\n",
    "          'optimizer': 1}\n",
    "\n",
    "param = {'padding_mode': 'zeros',\n",
    "         'depth': 3,\n",
    "         'start_layers': 32,\n",
    "         'dim_multiplier': 2,\n",
    "         'input_conv_kernel_size': 3,\n",
    "         'out_classes': 2,\n",
    "         'criterion': nn.CrossEntropyLoss(),\n",
    "         'optimizer': 1,\n",
    "         'augment_transform': T.Compose([T.RandomVerticalFlip()]),\n",
    "         'num_augments': 10,\n",
    "         'binarizer_lr': 0.05,\n",
    "         'batch_size': 1}\n",
    "\n",
    "unet_hyps = MultiHyperparameter(params)\n",
    "unet = UNet.__new__(UNet)\n",
    "\n",
    "models_to_evaluate = [(unet, unet_hyps)]\n",
    "\n",
    "num_epochs = 1\n",
    "models = []\n",
    "trainers = []\n",
    "folds = [0, 1, 2, 3]\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "cwd = os.getcwd()\n",
    "ds1_path = os.path.join(cwd, '../data/cell_type_1')\n",
    "ds2_path = os.path.join(cwd, '../data/cell_type_2')\n",
    "result_path = os.path.join(cwd, '../results')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'padding_mode': 'zeros', 'depth': 3, 'start_layers': 32, 'dim_multiplier': 2, 'input_conv_kernel_size': 3, 'out_classes': 2, 'criterion': CrossEntropyLoss(), 'optimizer': 1, 'augment_transform': Compose(\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "), 'num_augments': 10, 'binarizer_lr': 0.05, 'batch_size': 1}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m cte \u001B[38;5;241m=\u001B[39m CrossTrainEvaluator(unet, [ds1_path, ds2_path], device, result_path)\n\u001B[1;32m----> 2\u001B[0m report \u001B[38;5;241m=\u001B[39m \u001B[43mcte\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(report)\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\evaluate\\cross_evaluator.py:41\u001B[0m, in \u001B[0;36mCrossTrainEvaluator.evaluate_param\u001B[1;34m(self, param, folds, num_epochs)\u001B[0m\n\u001B[0;32m     37\u001B[0m ds_validate \u001B[38;5;241m=\u001B[39m SemanticDataset(dataset_path, folds_validate)\n\u001B[0;32m     38\u001B[0m trainer \u001B[38;5;241m=\u001B[39m UnetTrainer(current_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcriterion\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     39\u001B[0m                       th\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(current_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m),\n\u001B[0;32m     40\u001B[0m                       ds_train, ds_validate, param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maugment_transform\u001B[39m\u001B[38;5;124m'\u001B[39m], param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_augments\u001B[39m\u001B[38;5;124m'\u001B[39m], param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch_size\u001B[39m\u001B[38;5;124m'\u001B[39m], Binarizer2Class(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbinarizer_lr\u001B[39m\u001B[38;5;124m'\u001B[39m]), num_classes\u001B[38;5;241m=\u001B[39mparam[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout_classes\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 41\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     42\u001B[0m train_loss, validation_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mget_losses()\n\u001B[0;32m     43\u001B[0m train_losses \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_loss\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\train\\unet_trainer.py:33\u001B[0m, in \u001B[0;36mUnetTrainer.train\u001B[1;34m(self, epochs, test)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrain_epoch()\n\u001B[1;32m---> 33\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\train\\unet_trainer.py:84\u001B[0m, in \u001B[0;36mUnetTrainer.test\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     81\u001B[0m     data_binarizer\u001B[38;5;241m.\u001B[39mappend((target_store, pred_store))\n\u001B[0;32m     83\u001B[0m loader \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(data_binarizer, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m---> 84\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbinarizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     86\u001B[0m random_img \u001B[38;5;241m=\u001B[39m random_target \u001B[38;5;241m=\u001B[39m random_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     88\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m j, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtestloader, \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\postprocessing\\binarization.py:25\u001B[0m, in \u001B[0;36mBinarizer2Class.train\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m     23\u001B[0m     target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     24\u001B[0m     pred \u001B[38;5;241m=\u001B[39m pred\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 25\u001B[0m     acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43miou\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     26\u001B[0m acc \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(loader)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m best_acc \u001B[38;5;241m<\u001B[39m acc:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cte = CrossTrainEvaluator(unet, [ds1_path, ds2_path], device, result_path)\n",
    "report = cte.evaluate_param(param, [0, 1, 2, 3], 20)\n",
    "\n",
    "print(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.6000000000000001\n",
      "0.7000000000000001\n",
      "0.8\n",
      "0.9\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[[[0, 0, 0,  ..., 0, 0, 1],\n          [0, 0, 0,  ..., 0, 1, 0],\n          [0, 0, 0,  ..., 1, 0, 0],\n          ...,\n          [1, 0, 0,  ..., 0, 0, 0],\n          [1, 0, 0,  ..., 0, 1, 0],\n          [0, 1, 1,  ..., 0, 0, 0]],\n\n         [[0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          ...,\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 1, 0, 0]]],\n\n\n        [[[0, 0, 1,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 1, 0],\n          ...,\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0]],\n\n         [[0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          ...,\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0],\n          [0, 0, 0,  ..., 0, 0, 0]]]], device='cuda:0')"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from postprocessing.binarization import Binarizer2Class\n",
    "\n",
    "ds = SemanticDataset(ds1_path, [1])\n",
    "test_unet = UNet(param).to(device)\n",
    "binar = Binarizer2Class(device, 0.1, initial_threshold=0.5)\n",
    "\n",
    "loader = th.utils.data.DataLoader(ds, batch_size=1, shuffle=True)\n",
    "#\n",
    "data = []\n",
    "#\n",
    "for item in loader:\n",
    "    img, target = item\n",
    "    target_store = target.clone().detach().to('cpu')\n",
    "    target_store = target_store.to(th.int32)\n",
    "    img = img.to(device)\n",
    "    pred = test_unet.forward(img)\n",
    "    pred_store = pred.clone().detach().to('cpu')\n",
    "    data.append((target_store, pred_store))\n",
    "\n",
    "loader = th.utils.data.DataLoader(data, batch_size=1, shuffle=True)\n",
    "binar.train(loader)\n",
    "print(binar.threshold)\n",
    "binar.forward(th.rand((2, 2, 100, 100)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m loader \u001B[38;5;241m=\u001B[39m th\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;43mbin\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m(loader)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'builtin_function_or_method' object has no attribute 'train'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'padding_mode': 'zeros', 'depth': 5, 'start_layers': 64, 'dim_multiplier': 2, 'input_conv_kernel_size': 3, 'out_classes': 2, 'criterion': CrossEntropyLoss(), 'optimizer': 1, 'augment_transform': Compose(\n",
      "    RandomVerticalFlip(p=0.5)\n",
      "), 'num_augments': 10}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m cte \u001B[38;5;241m=\u001B[39m CrossTrainEvaluator(unet, [ds1_path, ds2_path], device, result_path)\n\u001B[1;32m----> 2\u001B[0m report \u001B[38;5;241m=\u001B[39m \u001B[43mcte\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate_param\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\evaluate\\cross_evaluator.py:40\u001B[0m, in \u001B[0;36mCrossTrainEvaluator.evaluate_param\u001B[1;34m(self, param, folds, num_epochs)\u001B[0m\n\u001B[0;32m     36\u001B[0m ds_validate \u001B[38;5;241m=\u001B[39m SemanticDataset(dataset_path, folds_validate)\n\u001B[0;32m     37\u001B[0m trainer \u001B[38;5;241m=\u001B[39m UnetTrainer(current_model, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice, param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcriterion\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     38\u001B[0m                       th\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(current_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-4\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-5\u001B[39m),\n\u001B[0;32m     39\u001B[0m                       ds_train, ds_validate, \u001B[38;5;241m1\u001B[39m, param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maugment_transform\u001B[39m\u001B[38;5;124m'\u001B[39m], param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnum_augments\u001B[39m\u001B[38;5;124m'\u001B[39m], param[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mout_classes\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m---> 40\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     41\u001B[0m train_loss, validation_loss \u001B[38;5;241m=\u001B[39m trainer\u001B[38;5;241m.\u001B[39mget_losses()\n\u001B[0;32m     42\u001B[0m train_losses \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_loss\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\train\\unet_trainer.py:31\u001B[0m, in \u001B[0;36mUnetTrainer.train\u001B[1;34m(self, epochs, test)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mtrain\u001B[39m(\u001B[38;5;28mself\u001B[39m, epochs, test\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 31\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtest()\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\train\\unet_trainer.py:46\u001B[0m, in \u001B[0;36mUnetTrainer.train_epoch\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     44\u001B[0m target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     45\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 46\u001B[0m x_predicted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m j \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     49\u001B[0m     random_img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mcpu()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mnumpy()\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\custom_models\\unet_original.py:88\u001B[0m, in \u001B[0;36mUNet.forward\u001B[1;34m(self, input_tensor)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, input_tensor):\n\u001B[1;32m---> 88\u001B[0m     output_1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcnn1\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# output_1 = self.dropout(output_1)\u001B[39;00m\n\u001B[0;32m     90\u001B[0m     output_1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_1(output_1)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\container.py:141\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 141\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1106\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1107\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1109\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1110\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1111\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1112\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:447\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    446\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 447\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\TorchEnv\\lib\\site-packages\\torch\\nn\\modules\\conv.py:443\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[1;34m(self, input, weight, bias)\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[0;32m    441\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[0;32m    442\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[1;32m--> 443\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "cte = CrossTrainEvaluator(unet, [ds1_path, ds2_path], device, result_path)\n",
    "report = cte.evaluate_param(param, [0, 1, 2, 3], 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      4\u001B[0m test_unet \u001B[38;5;241m=\u001B[39m unet\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(param)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mbin\u001B[39m \u001B[38;5;241m=\u001B[39m Binarizer2Class(test_unet, device, \u001B[38;5;241m0.1\u001B[39m, \u001B[38;5;241m0.5\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;43mbin\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mth\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\workspace\\segmentation\\src\\postprocessing\\binarization.py:26\u001B[0m, in \u001B[0;36mBinarizer2Class.train\u001B[1;34m(self, trainloader)\u001B[0m\n\u001B[0;32m     24\u001B[0m target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m     25\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m---> 26\u001B[0m x_predicted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m(img)\n\u001B[0;32m     28\u001B[0m int_target \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mto(th\u001B[38;5;241m.\u001B[39mint32)\n\u001B[0;32m     29\u001B[0m acc \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39miou(x_predicted, int_target)\u001B[38;5;241m.\u001B[39mitem()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file = th.load(os.path.join(cwd, '../results/test.pt'))\n",
    "print(file[0]['criterion'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}